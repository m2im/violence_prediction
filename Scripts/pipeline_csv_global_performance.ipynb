{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d89b670-f565-4457-aef8-3ca49e5813fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-16 21:17:59.553496: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import evaluate\n",
    "\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "from datasets import load_from_disk\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e93d6fc-f5a8-4c57-abda-607f9af89687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options for models in the hub\n",
    "# m2im/XLMT-T_finetuned_violence_twitter\n",
    "# m2im/smallLabse_finetuned_twitter\n",
    "# m2im/labse_finetuned_twitter\n",
    "\n",
    "# Options for path_to_model_on_disk\n",
    "# /home/mmendieta/labse_finetuned_twitter/\n",
    "# /data3/mmendieta/models/xlmt_finetuned_twitter\n",
    "# /data3/mmendieta/models/smallLabse_finetuned_twitter\n",
    "\n",
    "# Options for path_to_tokenized datasets_on_disk\n",
    "# /data3/mmendieta/Violence_data/geo_corpus.0.0.1_tok_ds_small_labse_inference\n",
    "# /data3/mmendieta/Violence_data/geo_corpus.0.0.1_tok_ds_xlmt_inference\n",
    "# /data3/mmendieta/Violence_data/geo_corpus.0.0.1_tok_ds_labse_inference\n",
    "\n",
    "config = {\n",
    "    \"cuda_device\": 14,\n",
    "    \"path_to_model_on_disk\": \"/home/mmendieta/xlmt_finetuned_twitter/\", \n",
    "    \"model_ckpt\": \"m2im/labse_finetuned_twitter\",\n",
    "    \"max_length\": 32,\n",
    "    \"batch_size\": 512,\n",
    "    \"dataset_name\": \"/data3/mmendieta/Violence_data/geo_corpus.0.0.1_tok_ds_small_labse_inference\",\n",
    "    \"fout\": \"/data3/mmendieta/Violence_data/csv_files_global_scale/small_labse_inference_test_set.csv\"\n",
    "}\n",
    "\n",
    "args = Namespace(**config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ea152c",
   "metadata": {},
   "source": [
    "# 1. Instantiate the required pipeline\n",
    "Choose of the three pipelines of interest. The XLM-T pipeline is the best performing model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26145bf4",
   "metadata": {},
   "source": [
    "### LaBSE pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fafc2b-9979-402a-94a3-ff14109e7ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "violence_pipe = pipeline(\"text-classification\",\n",
    "                         model=\"m2im/labse_finetuned_twitter\", \n",
    "                         device=args.cuda_device,\n",
    "                         return_all_scores=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d76bf8",
   "metadata": {},
   "source": [
    "### small-LaBSE pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87d088c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a980d75c3e4970a642f57851e95d2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.16k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-16 21:18:24.886029: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-12-16 21:18:24.886968: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2024-12-16 21:18:26.056559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:1e:00.0 name: Tesla V100-SXM3-32GB computeCapability: 7.0\n",
      "coreClock: 1.597GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 913.62GiB/s\n",
      "2024-12-16 21:18:26.057706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:23:00.0 name: Tesla V100-SXM3-32GB computeCapability: 7.0\n",
      "coreClock: 1.597GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 913.62GiB/s\n",
      "2024-12-16 21:18:26.058773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: \n",
      "pciBusID: 0000:28:00.0 name: Tesla V100-SXM3-32GB computeCapability: 7.0\n",
      "coreClock: 1.597GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 913.62GiB/s\n",
      "2024-12-16 21:18:26.059842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties: \n",
      "pciBusID: 0000:2d:00.0 name: Tesla V100-SXM3-32GB computeCapability: 7.0\n",
      "coreClock: 1.597GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 913.62GiB/s\n",
      "2024-12-16 21:18:26.060911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 4 with properties: \n",
      "pciBusID: 0000:41:00.0 name: Tesla V100-SXM3-32GB computeCapability: 7.0\n",
      "coreClock: 1.597GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 913.62GiB/s\n",
      "2024-12-16 21:18:26.061966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 5 with properties: \n",
      "pciBusID: 0000:42:00.0 name: Tesla V100-SXM3-32GB computeCapability: 7.0\n",
      "coreClock: 1.597GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 913.62GiB/s\n",
      "2024-12-16 21:18:26.063029: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 6 with properties: \n",
      "pciBusID: 0000:4c:00.0 name: Tesla V100-SXM3-32GB computeCapability: 7.0\n",
      "coreClock: 1.597GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 913.62GiB/s\n",
      "2024-12-16 21:18:26.064091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 7 with properties: \n",
      "pciBusID: 0000:4d:00.0 name: Tesla V100-SXM3-32GB computeCapability: 7.0\n",
      "coreClock: 1.597GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 913.62GiB/s\n",
      "2024-12-16 21:18:26.065148: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 8 with properties: \n",
      "pciBusID: 0000:8c:00.0 name: Tesla V100-SXM3-32GB computeCapability: 7.0\n",
      "coreClock: 1.597GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 913.62GiB/s\n",
      "2024-12-16 21:18:26.066204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 9 with properties: \n",
      "pciBusID: 0000:91:00.0 name: Tesla V100-SXM3-32GB computeCapability: 7.0\n",
      "coreClock: 1.597GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 913.62GiB/s\n",
      "2024-12-16 21:18:26.067261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 10 with properties: \n",
      "pciBusID: 0000:96:00.0 name: Tesla V100-SXM3-32GB computeCapability: 7.0\n",
      "coreClock: 1.597GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 913.62GiB/s\n",
      "2024-12-16 21:18:26.068333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 11 with properties: \n",
      "pciBusID: 0000:9b:00.0 name: Tesla V100-SXM3-32GB computeCapability: 7.0\n",
      "coreClock: 1.597GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 913.62GiB/s\n",
      "2024-12-16 21:18:26.069395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 12 with properties: \n",
      "pciBusID: 0000:b5:00.0 name: Tesla V100-SXM3-32GB computeCapability: 7.0\n",
      "coreClock: 1.597GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 913.62GiB/s\n",
      "2024-12-16 21:18:26.070441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 13 with properties: \n",
      "pciBusID: 0000:b6:00.0 name: Tesla V100-SXM3-32GB computeCapability: 7.0\n",
      "coreClock: 1.597GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 913.62GiB/s\n",
      "2024-12-16 21:18:26.071505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 14 with properties: \n",
      "pciBusID: 0000:c0:00.0 name: Tesla V100-SXM3-32GB computeCapability: 7.0\n",
      "coreClock: 1.597GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 913.62GiB/s\n",
      "2024-12-16 21:18:26.072569: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 15 with properties: \n",
      "pciBusID: 0000:c1:00.0 name: Tesla V100-SXM3-32GB computeCapability: 7.0\n",
      "coreClock: 1.597GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 913.62GiB/s\n",
      "2024-12-16 21:18:26.072616: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2024-12-16 21:18:26.075399: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2024-12-16 21:18:26.075526: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2024-12-16 21:18:26.076500: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2024-12-16 21:18:26.076799: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2024-12-16 21:18:26.076914: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.1/lib64:\n",
      "2024-12-16 21:18:26.077496: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2024-12-16 21:18:26.077631: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2024-12-16 21:18:26.077639: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-12-16 21:18:26.078266: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-16 21:18:26.081154: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-12-16 21:18:26.081178: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-12-16 21:18:26.081182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      \n"
     ]
    }
   ],
   "source": [
    "violence_pipe = pipeline(model=\"m2im/smallLabse_finetuned_twitter\", \n",
    "                         device=args.cuda_device,\n",
    "                         return_all_scores=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9a818c",
   "metadata": {},
   "source": [
    "### XLM-T pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43311793",
   "metadata": {},
   "outputs": [],
   "source": [
    "violence_pipe = pipeline(model=\"m2im/XLM-T_finetuned_violence_twitter\", \n",
    "                         device=args.cuda_device,\n",
    "                         return_all_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4414c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the pipeline. Use a short text just like you would do in a twitter. \n",
    "# Keep in mind that we are not doing any text preprocessing for this test case.\n",
    "text = \"today is a sunny day\"\n",
    "outputs = violence_pipe(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb99b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85c0748",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c3e04d",
   "metadata": {},
   "source": [
    "# 2. Use the pipeline to make predictions with the violence dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345dbf47",
   "metadata": {},
   "source": [
    "### Load the tokenized test dataset to disk\n",
    "This is the tokenized dataset that includes the columns *text*, *tweetid*, *geo_x*, *geo_y*, and *lang*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6b375c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tok = load_from_disk(args.dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6997ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a subsmample for testing purposes\n",
    "test_tokenized_ds_sample = ds_tok.shuffle().select(range(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36499097",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tokenized_ds_sample[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376ad133",
   "metadata": {},
   "source": [
    "### a. Single sample (pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbf2e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = test_tokenized_ds_sample[10]\n",
    "print(f\"Text: {sample['text']} | Language: {sample['lang']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c8ee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = violence_pipe(sample['text'])\n",
    "pd.DataFrame(outputs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802a2ec6",
   "metadata": {},
   "source": [
    "### b. Multiple sample pipeline (visualizing text, true labels, predictions, and other columns)\n",
    "Make sure to select the apropriate batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adbd138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For samples only\n",
    "preds = []\n",
    "\n",
    "for i, outputs in enumerate(tqdm(violence_pipe(KeyDataset(test_tokenized_ds_sample, \"text\"), \n",
    "                                               batch_size=args.batch_size,\n",
    "                                               truncation=True),\n",
    "                                 total=len(test_tokenized_ds_sample))):\n",
    "    text = test_tokenized_ds_sample[i]['text']\n",
    "    labels = test_tokenized_ds_sample[i]['labels'].tolist()\n",
    "    tweetid = test_tokenized_ds_sample[i]['tweetid']\n",
    "    lang = test_tokenized_ds_sample[i]['lang']\n",
    "    geo_x = float(test_tokenized_ds_sample[i]['geo_x']) # cast tensor to float\n",
    "    geo_y = float(test_tokenized_ds_sample[i]['geo_y']) # cast tensor to float\n",
    "    preds.append({\n",
    "        'tweetid': tweetid,\n",
    "        'text': text,\n",
    "        'lang': lang,\n",
    "        'geo_x': geo_x,\n",
    "        'geo_y': geo_y,\n",
    "        'labels': labels,\n",
    "        'outputs': outputs\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1165d739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ced81317c87248adb94a65dbd3e0db45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2329158 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = []\n",
    "\n",
    "for i, outputs in enumerate(tqdm(violence_pipe(KeyDataset(ds_tok, \"text\"), batch_size=args.batch_size,\n",
    "                                              truncation=True),\n",
    "                                 total=len(ds_tok))):\n",
    "    text = ds_tok[i]['text']\n",
    "    labels = ds_tok[i]['labels'].tolist()\n",
    "    tweetid = ds_tok[i]['tweetid']\n",
    "    lang = ds_tok[i]['lang']\n",
    "    geo_x = float(ds_tok[i]['geo_x']) # cast tensor to float\n",
    "    geo_y = float(ds_tok[i]['geo_y']) # cast tensor to float\n",
    "    preds.append({\n",
    "        'tweetid': tweetid,\n",
    "        'text': text,\n",
    "        'lang': lang,\n",
    "        'geo_x': geo_x,\n",
    "        'geo_y': geo_y,\n",
    "        'labels': labels,\n",
    "        'outputs': outputs\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac77034a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92bd13b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = []\n",
    "for pred in preds:\n",
    "    row = {\n",
    "        'tweetid': pred['tweetid'],  # Include tweet ID\n",
    "        'text': pred['text'],        # Include text\n",
    "        'lang': pred['lang'],        # Include language\n",
    "        'geo_x': pred['geo_x'],      # Include geo_x coordinate\n",
    "        'geo_y': pred['geo_y'],      # Include geo_y coordinate\n",
    "    }\n",
    "    \n",
    "    # True labels for each column\n",
    "    row['post7geo10_true'] = pred['labels'][0]\n",
    "    row['post7geo30_true'] = pred['labels'][1]\n",
    "    row['post7geo50_true'] = pred['labels'][2]\n",
    "    row['pre7geo10_true'] = pred['labels'][3]\n",
    "    row['pre7geo30_true'] = pred['labels'][4]\n",
    "    row['pre7geo50_true'] = pred['labels'][5]\n",
    "    \n",
    "    # Predicted scores for each column\n",
    "    row['post7geo10'] = pred['outputs'][0]['score']\n",
    "    row['post7geo30'] = pred['outputs'][1]['score']\n",
    "    row['post7geo50'] = pred['outputs'][2]['score']\n",
    "    row['pre7geo10'] = pred['outputs'][3]['score']\n",
    "    row['pre7geo30'] = pred['outputs'][4]['score']\n",
    "    row['pre7geo50'] = pred['outputs'][5]['score']\n",
    "    \n",
    "    processed_data.append(row)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d3d372a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns for the specified order\n",
    "df = df[['tweetid', 'text', 'lang', 'geo_x', 'geo_y',\n",
    "         'post7geo10_true', 'post7geo30_true', 'post7geo50_true', \n",
    "         'pre7geo10_true', 'pre7geo30_true', 'pre7geo50_true',\n",
    "         'post7geo10', 'post7geo30', 'post7geo50',\n",
    "         'pre7geo10', 'pre7geo30', 'pre7geo50']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "878477a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "      <th>geo_x</th>\n",
       "      <th>geo_y</th>\n",
       "      <th>post7geo10_true</th>\n",
       "      <th>post7geo30_true</th>\n",
       "      <th>post7geo50_true</th>\n",
       "      <th>pre7geo10_true</th>\n",
       "      <th>pre7geo30_true</th>\n",
       "      <th>pre7geo50_true</th>\n",
       "      <th>post7geo10</th>\n",
       "      <th>post7geo30</th>\n",
       "      <th>post7geo50</th>\n",
       "      <th>pre7geo10</th>\n",
       "      <th>pre7geo30</th>\n",
       "      <th>pre7geo50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>487300699391524864</td>\n",
       "      <td>#Baloncesto | El seguro ha retrasado la incorp...</td>\n",
       "      <td>es</td>\n",
       "      <td>-66.879189</td>\n",
       "      <td>10.488010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.301021</td>\n",
       "      <td>0.447158</td>\n",
       "      <td>0.561377</td>\n",
       "      <td>0.335758</td>\n",
       "      <td>0.460488</td>\n",
       "      <td>0.589329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>447660809615716352</td>\n",
       "      <td>？あなたの質問はモンゴル語ができるかどうかは、関係ないと思いますが。</td>\n",
       "      <td>ja</td>\n",
       "      <td>34.333328</td>\n",
       "      <td>31.416670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.280725</td>\n",
       "      <td>0.532827</td>\n",
       "      <td>0.531862</td>\n",
       "      <td>0.300278</td>\n",
       "      <td>0.515056</td>\n",
       "      <td>0.511221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>490608380818776065</td>\n",
       "      <td>الحمدلله</td>\n",
       "      <td>ar</td>\n",
       "      <td>35.203289</td>\n",
       "      <td>31.921570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.374464</td>\n",
       "      <td>0.555044</td>\n",
       "      <td>0.633924</td>\n",
       "      <td>0.384644</td>\n",
       "      <td>0.565593</td>\n",
       "      <td>0.642552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>481456072243552256</td>\n",
       "      <td>Ben hocaları ders konuşan resmi insanlar sanır...</td>\n",
       "      <td>tr</td>\n",
       "      <td>36.567219</td>\n",
       "      <td>36.269169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004120</td>\n",
       "      <td>0.083924</td>\n",
       "      <td>0.563934</td>\n",
       "      <td>0.003861</td>\n",
       "      <td>0.079940</td>\n",
       "      <td>0.549076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>476767010660294657</td>\n",
       "      <td>#11J</td>\n",
       "      <td>und</td>\n",
       "      <td>-66.879189</td>\n",
       "      <td>10.488010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.024238</td>\n",
       "      <td>0.027190</td>\n",
       "      <td>0.027362</td>\n",
       "      <td>0.956298</td>\n",
       "      <td>0.979338</td>\n",
       "      <td>0.986539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tweetid                                               text  \\\n",
       "60  487300699391524864  #Baloncesto | El seguro ha retrasado la incorp...   \n",
       "61  447660809615716352                 ？あなたの質問はモンゴル語ができるかどうかは、関係ないと思いますが。   \n",
       "62  490608380818776065                                           الحمدلله   \n",
       "63  481456072243552256  Ben hocaları ders konuşan resmi insanlar sanır...   \n",
       "64  476767010660294657                                               #11J   \n",
       "\n",
       "   lang      geo_x      geo_y  post7geo10_true  post7geo30_true  \\\n",
       "60   es -66.879189  10.488010              1.0              1.0   \n",
       "61   ja  34.333328  31.416670              0.0              0.0   \n",
       "62   ar  35.203289  31.921570              0.0              0.0   \n",
       "63   tr  36.567219  36.269169              0.0              1.0   \n",
       "64  und -66.879189  10.488010              0.0              0.0   \n",
       "\n",
       "    post7geo50_true  pre7geo10_true  pre7geo30_true  pre7geo50_true  \\\n",
       "60              1.0             0.0             0.0             0.0   \n",
       "61              0.0             0.0             0.0             0.0   \n",
       "62              0.0             1.0             1.0             1.0   \n",
       "63              1.0             0.0             1.0             1.0   \n",
       "64              0.0             1.0             1.0             1.0   \n",
       "\n",
       "    post7geo10  post7geo30  post7geo50  pre7geo10  pre7geo30  pre7geo50  \n",
       "60    0.301021    0.447158    0.561377   0.335758   0.460488   0.589329  \n",
       "61    0.280725    0.532827    0.531862   0.300278   0.515056   0.511221  \n",
       "62    0.374464    0.555044    0.633924   0.384644   0.565593   0.642552  \n",
       "63    0.004120    0.083924    0.563934   0.003861   0.079940   0.549076  \n",
       "64    0.024238    0.027190    0.027362   0.956298   0.979338   0.986539  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[60:65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d603737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe to disk\n",
    "df.to_csv(args.fout, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5565d9eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
