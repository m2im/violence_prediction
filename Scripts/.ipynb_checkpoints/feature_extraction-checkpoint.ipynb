{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "248f2895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_from_disk\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dde9808",
   "metadata": {},
   "source": [
    "### Read the dataset and delete unneccessary colums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8681a4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "violence = load_from_disk(\"../../Violence_data/geo_corpus.0.0.1_datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9d0e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "violence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9afb4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = violence[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ca737d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cd7f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b00fbb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_cols = ['tweetid', 'retweetid', 'date', 'timestamp', 'username', 'geo_x', 'geo_y', 'key']\n",
    "# remove_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb9a24e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "violence = violence.remove_columns(remove_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b742faa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(violence[\"train\"][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2c1fa8",
   "metadata": {},
   "source": [
    "### From text to tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e7e8c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e55d5ec418c429681c5b5cc9cc3ee4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/841 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "237e9c9051f54781a5e70ec8aee5bae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/4.83M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d63c2f266f9431a8813db57d4e7480a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load XLM-T: A Multilingual Language Model Toolkit for Twitter\n",
    "model_ckpt = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d1c143",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Tokenizing text is a core task of NLP\"\n",
    "encoded_text = tokenizer(text)\n",
    "print(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbe4a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert ids back into tokens\n",
    "tokens = tokenizer.convert_ids_to_tokens(encoded_text.input_ids)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e305ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.convert_tokens_to_string(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57407c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32e663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb22973",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.model_input_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b3dd71",
   "metadata": {},
   "source": [
    "### Tokenizing the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "565f2571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "     return tokenizer(batch[\"text\"], padding=True, truncation=True, max_length=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336b4821",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenize(violence[\"train\"].select(range(1000))[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ab6c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d485ca78a50e4e7f9572c757951b4ab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1677 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenizing the entire dataset\n",
    "# %time violence_encoded = violence[\"train\"].select(range(1000)).map(tokenize, batched=True, batch_size=None)\n",
    "%time violence_encoded = violence.map(tokenize, batched=True, batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98be03bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "violence_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab25ec78",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2566ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModel.from_pretrained(model_ckpt).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7b11b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract last hidden state\n",
    "text = \"this is a very interesting text\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "print(f\"Input tensor shape: {inputs['input_ids'].size()}\") # [batch_size, n_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30175bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {k:v.to(device) for k,v in inputs.items()}\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49c1fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.last_hidden_state.size() # batch_size, n_tokens, hidden_dim (768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0b4191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract CLS token\n",
    "outputs.last_hidden_state[:,0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c4db65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to extract hidden state\n",
    "def extract_hidden_states(batch):\n",
    "    # Place model inputs on the GPU\n",
    "    inputs = {k:v.to(device) for k,v in batch.items()\n",
    "             if k in tokenizer.model_input_names}\n",
    "    # Extract last hidden states\n",
    "    with torch.no_grad():\n",
    "        last_hidden_state = model(**inputs).last_hidden_state\n",
    "    # Return vector for [CLS] token\n",
    "    return {\"hidden_state\": last_hidden_state[:,0].cpu().numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00855e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "violence_encoded.set_format(\"torch\",\n",
    "                           columns=[\"input_ids\", \"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41729d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time violence_hidden = violence_encoded.map(extract_hidden_states, \n",
    "                                             batched=True, batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb145c2",
   "metadata": {},
   "source": [
    "### Save dataset (including the tokenizer) to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179932ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "violence_hidden[\"train\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06690c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time violence_hidden.save_to_disk(\"../../Violence_data/geo_corpus.0.0.1_datasets_hidden_xlmt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fb90f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "violence_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15858140",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28a78ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
