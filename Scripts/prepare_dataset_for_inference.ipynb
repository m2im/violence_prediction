{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e02bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44460ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266b9abe",
   "metadata": {},
   "source": [
    "### Preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d0eef7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_from_disk(\"/data3/mmendieta/Violence_data/geo_corpus.0.0.1_datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d70c922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peek at one sample\n",
    "ds[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6c3bf7",
   "metadata": {},
   "source": [
    "Since this is a multi-label classification problem, there are 6 labels = ('pre7geo10', 'pre7geo30', 'pre7geo50', 'post7geo10', 'post7geo30', 'post7geo50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a68a3cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unncesary columns\n",
    "keep_cols = ['tweetid', 'text', 'geo_x', 'geo_y', 'lang', 'pre7geo10', 'pre7geo30', \n",
    "             'pre7geo50', 'post7geo10', 'post7geo30', 'post7geo50']\n",
    "remove_columns = [col for col in ds['train'].column_names if col not in keep_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "984fcf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.remove_columns(remove_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e4cde91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tweetid': Value(dtype='int64', id=None),\n",
       " 'geo_x': Value(dtype='float64', id=None),\n",
       " 'geo_y': Value(dtype='float64', id=None),\n",
       " 'lang': Value(dtype='string', id=None),\n",
       " 'text': Value(dtype='string', id=None),\n",
       " 'post7geo10': Value(dtype='int64', id=None),\n",
       " 'post7geo30': Value(dtype='int64', id=None),\n",
       " 'post7geo50': Value(dtype='int64', id=None),\n",
       " 'pre7geo10': Value(dtype='int64', id=None),\n",
       " 'pre7geo30': Value(dtype='int64', id=None),\n",
       " 'pre7geo50': Value(dtype='int64', id=None)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82da609b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /data3/mmendieta/Violence_data/geo_corpus.0.0.1_datasets/train/cache-8b2a0d7a6205e985.arrow\n",
      "Loading cached processed dataset at /data3/mmendieta/Violence_data/geo_corpus.0.0.1_datasets/validation/cache-85273bc4be4fa313.arrow\n",
      "Loading cached processed dataset at /data3/mmendieta/Violence_data/geo_corpus.0.0.1_datasets/test/cache-36890463b6b802a7.arrow\n"
     ]
    }
   ],
   "source": [
    "# We need to to cast integer labels to float in order to calculate the Binary Cross\n",
    "# Entropy loss during training\n",
    "from datasets import Value\n",
    "new_features = ds[\"train\"].features.copy()\n",
    "new_features['tweetid'] = Value(dtype='string')  # cast this value to integer to avoid errors\n",
    "new_features['post7geo10'] = Value(dtype='float32')\n",
    "new_features['post7geo30'] = Value(dtype='float32')\n",
    "new_features['post7geo50'] = Value(dtype='float32')\n",
    "new_features['pre7geo10'] = Value(dtype='float32')\n",
    "new_features['pre7geo30'] = Value(dtype='float32')\n",
    "new_features['pre7geo50'] = Value(dtype='float32')\n",
    "ds[\"train\"] = ds[\"train\"].cast(new_features)\n",
    "ds[\"validation\"] = ds[\"validation\"].cast(new_features)\n",
    "ds[\"test\"] = ds[\"test\"].cast(new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22cab616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tweetid': Value(dtype='string', id=None),\n",
       " 'geo_x': Value(dtype='float64', id=None),\n",
       " 'geo_y': Value(dtype='float64', id=None),\n",
       " 'lang': Value(dtype='string', id=None),\n",
       " 'text': Value(dtype='string', id=None),\n",
       " 'post7geo10': Value(dtype='float32', id=None),\n",
       " 'post7geo30': Value(dtype='float32', id=None),\n",
       " 'post7geo50': Value(dtype='float32', id=None),\n",
       " 'pre7geo10': Value(dtype='float32', id=None),\n",
       " 'pre7geo30': Value(dtype='float32', id=None),\n",
       " 'pre7geo50': Value(dtype='float32', id=None)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0d20974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38f7477f50b1430e951efc1cc63579fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2329158 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['tweetid', 'geo_x', 'geo_y', 'lang', 'text', 'labels'],\n",
       "    num_rows: 2329158\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell takes approximately 4 min to run\n",
    "# It is important that the labels are float in order to calculate Binary Cross Entropy loss\n",
    "# create 'labels' columm\n",
    "\n",
    "# Define columns to ignore\n",
    "ignore_columns = [\"tweetid\", \"geo_x\", \"geo_y\", \"lang\", \"text\"]\n",
    "\n",
    "# Filter to only work on the test set\n",
    "cols = [col for col in ds[\"test\"].column_names if col not in ignore_columns]\n",
    "\n",
    "# Map function to create labels\n",
    "ds[\"test\"] = ds[\"test\"].map(lambda x: {\"labels\": [x[c] for c in cols]}, remove_columns=cols)\n",
    "\n",
    "ds['test']                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d00e1d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tweetid': '388328898662268928',\n",
       " 'geo_x': 35.49442,\n",
       " 'geo_y': 33.888940000000005,\n",
       " 'lang': 'en',\n",
       " 'text': 'talking abt my case ☺️',\n",
       " 'labels': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"test\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f156cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['test'].save_to_disk(\"/data3/mmendieta/Violence_data/geo_corpus.0.0.1_dataset_for_inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fe073d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
