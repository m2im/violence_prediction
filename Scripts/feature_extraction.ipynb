{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "248f2895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_from_disk, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2241020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possible values\n",
    "# Smaller-LABSE: setu4993/smaller-LaBSE\n",
    "# Smaller-LABSE: /data3/mmendieta/models/small_labse\n",
    "# LABSE: setu4993/LaBSE\n",
    "# LABSE: /data3/mmendieta/models/labse\n",
    "# XLMT: cardiffnlp/twitter-xlm-roberta-base-sentiment\n",
    "# XLMT: /data3/mmendieta/models/xlmt\n",
    "# ML-E5-LARGE: /data3/mmendieta/models/ml_e5_large \n",
    "config = {\n",
    "    \"model_ckpt\": \"/data3/mmendieta/models/ml_e5_large\",\n",
    "    \"batch_size\": 1024,\n",
    "    \"max_length\": 32,\n",
    "    \"cuda_device\": \"cuda:0\",\n",
    "    \"seed\": 42,\n",
    "    \"dataset\": \"/data3/mmendieta/Violence_data/geo_corpus.0.0.1_dataset_for_train_all_labels\",\n",
    "    \"output_dir_ckpt\": \"/data4/mmendieta/data/geo_corpus.0.0.1_datasets_hidden_e5_all_labels\"\n",
    "}\n",
    "\n",
    "args = Namespace(**config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dde9808",
   "metadata": {},
   "source": [
    "### Read the dataset and delete unneccessary colums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8681a4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "violence = load_from_disk(args.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d9d0e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 16769932\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 4192483\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 2329158\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "violence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9afb4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = violence[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ca737d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cd7f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2c1fa8",
   "metadata": {},
   "source": [
    "### From text to tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e7e8c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model checkpoint\n",
    "model_ckpt = args.model_ckpt\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d1c143",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Tokenizing text is a core task of NLP\"\n",
    "encoded_text = tokenizer(text)\n",
    "print(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbe4a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert ids back into tokens\n",
    "tokens = tokenizer.convert_ids_to_tokens(encoded_text.input_ids)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e305ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.convert_tokens_to_string(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57407c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32e663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb22973",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.model_input_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b3dd71",
   "metadata": {},
   "source": [
    "### Tokenizing the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "565f2571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "     return tokenizer(batch[\"text\"], padding=True, truncation=True, max_length=args.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336b4821",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenize(violence[\"train\"].select(range(1000))[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97c5e16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [WARNING:] Run the next 2 following cells only if you want to sample the dataset and then tokenize it\n",
    "# Sample the required number of rows from each split\n",
    "train_sample = violence[\"train\"].shuffle(seed=42).select(range(1500000))\n",
    "val_sample = violence[\"validation\"].shuffle(seed=42).select(range(400000))\n",
    "test_sample = violence[\"test\"].shuffle(seed=42).select(range(200000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a0b2860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DatasetDict\n",
    "violence_sampled = DatasetDict({\n",
    "    \"train\": train_sample,\n",
    "    \"validation\": val_sample,\n",
    "    \"test\": test_sample\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6ab6c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c9a8263b684d67a0c2ce3c286a1066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1465 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cb83ba7de4c4b30ad13ff7fcc014dd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7006b5fc517c4ef7849da10288ec0ae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21min 39s, sys: 50 s, total: 22min 29s\n",
      "Wall time: 2min 17s\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing the entire dataset\n",
    "# %time violence_encoded = violence[\"train\"].select(range(1000)).map(tokenize, batched=True, batch_size=None)\n",
    "# %time violence_encoded = violence.map(tokenize, batched=True, batch_size=args.batch_size)\n",
    "%time violence_encoded = violence_sampled.map(tokenize, batched=True, batch_size=args.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98be03bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "violence_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab25ec78",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d2566ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(args.cuda_device if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModel.from_pretrained(model_ckpt).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7b11b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract last hidden state\n",
    "text = \"this is a very interesting text\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "print(f\"Input tensor shape: {inputs['input_ids'].size()}\") # [batch_size, n_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30175bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {k:v.to(device) for k,v in inputs.items()}\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49c1fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.last_hidden_state.size() # batch_size, n_tokens, hidden_dim (768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0b4191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract CLS token\n",
    "outputs.last_hidden_state[:,0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53c4db65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to extract hidden state\n",
    "def extract_hidden_states(batch):\n",
    "    # Place model inputs on the GPU\n",
    "    inputs = {k:v.to(device) for k,v in batch.items()\n",
    "             if k in tokenizer.model_input_names}\n",
    "    # Extract last hidden states\n",
    "    with torch.no_grad():\n",
    "        last_hidden_state = model(**inputs).last_hidden_state\n",
    "    # Return vector for [CLS] token\n",
    "    return {\"hidden_state\": last_hidden_state[:,0].cpu().numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a0f477",
   "metadata": {},
   "outputs": [],
   "source": [
    "violence_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d00855e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "violence_encoded.set_format(\"torch\",\n",
    "                           columns=[\"input_ids\", \"attention_mask\", \n",
    "                                    \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c41729d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4191e31f0aa64120999f317ecec62716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1465 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55cbb466182c4ea9b679d358d6f36563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "440291868c684e0a97dc680478fe3f72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 23min 47s, sys: 17.7 s, total: 1h 24min 5s\n",
      "Wall time: 54min 20s\n"
     ]
    }
   ],
   "source": [
    "%time violence_hidden = violence_encoded.map(extract_hidden_states, batched=True, batch_size=args.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb145c2",
   "metadata": {},
   "source": [
    "### Save dataset (including the tokenizer) to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "179932ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': Value(dtype='string', id=None),\n",
       " 'labels': Sequence(feature=Value(dtype='float64', id=None), length=-1, id=None),\n",
       " 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
       " 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
       " 'hidden_state': Sequence(feature=Value(dtype='float32', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "violence_hidden[\"train\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06690c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 262 ms, sys: 5.19 s, total: 5.45 s\n",
      "Wall time: 5.45 s\n"
     ]
    }
   ],
   "source": [
    "%time violence_hidden.save_to_disk(args.output_dir_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15858140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'labels', 'input_ids', 'attention_mask', 'hidden_state'],\n",
       "        num_rows: 1500000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'labels', 'input_ids', 'attention_mask', 'hidden_state'],\n",
       "        num_rows: 400000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'labels', 'input_ids', 'attention_mask', 'hidden_state'],\n",
       "        num_rows: 200000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "violence_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28a78ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
